import numpy as np
import matplotlib.pyplot as plt

# 셈플에 활용할 데이터셋 만들기
def make_linear(w = 0.5, b = 0.8, size = 50, noise = 1.0):
    x = np.random.rand(size)
    y = w * x + b

    noise = np.random.uniform(-abs(noise), abs(noise), size=y.shape)

    yy = y + noise
    plt.figure(figsize=(10, 7))

    plt.plot(x, y, color='r', label=f'y = {w} * x + {b}')
    plt.scatter(x, yy, label='data')

    plt.legend(fontsize=20)
    plt.show()

    print(f'w: {w}, b: {b}')
    return x, yy

x, y = make_linear(w = 0.3, b = 0.5, size=100, noise= 0.01)

# 2.
# 최대 반복 횟수
num_epoch = 1000

# 학습률(learning_rate)
learning_rate = 0.005

# 에러 기록
errors = []

# random 한 값으로 w, b를 초기화
w = np.random.uniform(low=0.0, high=1.0)
b = np.random.uniform(low=0.0, high=1.0)

for epoch in range(num_epoch):
    # Hypothesis 정의
    y_hat = w * x + b

    # Loss Function 정의
    error = 0.5 * ((y_hat - y) ** 2).sum()

    if error < 0.005:
        break;
    
    # Gradient 미분 계산
    w = w - learning_rate * ((y_hat - y) * x).sum()
    b = b - learning_rate * (y_hat - y).sum()

    errors.append(error)

    if epoch % 5 == 0:
        print("{0:2} w = {1:.5f}, b={2:.5f} error={3:.5f}".format(epoch, w, b, error))

print("----" * 15)
print("{0:2}w = {1:.1f}, b={2:.1f} error={3:.5f}".format(epoch, w, b, error))

# 3.
plt.figure(figsize=(10, 7))
plt.plot(errors)
plt.xlabel("Epochs")
plt.ylabel("Error")
plt.show()